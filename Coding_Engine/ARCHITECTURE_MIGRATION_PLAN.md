# Architecture Migration Plan: Session Pool â†’ ACA Only

## ğŸ¯ Executive Summary

**Current**: Azure Session Pool (Dynamic Sessions) with Piston  
**Proposed**: Azure Container Apps (ACA) only with GitHub Actions + Terraform  
**Challenge**: Piston requires privileged mode, ACA doesn't support it

---

## ğŸ“Š Current vs Proposed Architecture

### Current Architecture (Session Pool)
```
User Request
    â†“
Backend (ACA) - Port 8000
    â†“
Session Pool (Dynamic Sessions)
    â†“
Container with Piston (privileged mode)
    â†“
Code Execution
```

**Pros**:
- âœ… Hyper-V isolation (hardware-level security)
- âœ… Automatic scaling
- âœ… Pay-per-use pricing
- âœ… No privileged mode issues (runs in Session Pool)

**Cons**:
- âš ï¸ Ingress configuration complexity
- âš ï¸ Session Pool is preview feature
- âš ï¸ Limited language support (custom images needed)

---

### Proposed Architecture (ACA Only)
```
User Request
    â†“
GitHub Actions (Request Queue/Spinner)
    â†“
Terraform Script (via GitHub Actions)
    â†“
Deploy New ACA Container per Request
    â†“
Code Execution in Container
    â†“
Cleanup Container
```

**Pros**:
- âœ… No privileged mode needed (if using alternatives)
- âœ… Full control over container lifecycle
- âœ… Standard ACA features (scaling, ingress)
- âœ… Infrastructure as Code (Terraform)

**Cons**:
- âŒ **Container creation overhead** (30-60 seconds per request)
- âŒ **Cost**: Each execution = new container = higher cost
- âŒ **Complexity**: GitHub Actions + Terraform orchestration
- âŒ **Security**: Container-level isolation (not hardware-level)
- âŒ **Scalability**: Limited by GitHub Actions concurrency

---

## ğŸ” Critical Analysis: Is This Feasible?

### âŒ Problem 1: Container Creation Latency

**Issue**: Creating a new ACA container per code execution takes **30-60 seconds**.

```
Request â†’ GitHub Actions â†’ Terraform â†’ ACA Deploy â†’ Execute â†’ Cleanup
         (5-10s)         (20-30s)    (10-20s)     (1-5s)   (5-10s)
Total: ~50-75 seconds per code execution
```

**Impact**: 
- Users wait 50-75 seconds for code execution
- Not suitable for real-time coding contests
- Poor user experience

**Current Session Pool**: ~1-3 seconds (container already running)

---

### âŒ Problem 2: GitHub Actions as Request Queue

**Limitations**:
- GitHub Actions has **concurrency limits**:
  - Free: 20 concurrent jobs
  - Pro: 40 concurrent jobs
  - Enterprise: 180 concurrent jobs
- **Not designed for request queuing**
- **Rate limiting**: 1000 API calls/hour per repository
- **Cost**: GitHub Actions minutes cost money at scale

**Better Alternatives**:
- Azure Service Bus (proper message queue)
- Azure Queue Storage
- Azure Functions (event-driven)
- Azure Logic Apps

---

### âŒ Problem 3: Piston Alternative Needed

**Why Piston Needs Privileged Mode**:
- Piston dynamically creates/manages containers
- Requires Docker daemon access
- Needs `CAP_SYS_ADMIN` capabilities

**Alternatives That Work in ACA**:

#### Option A: **Code-Server / Theia** (Browser-based IDE)
- âœ… No privileged mode needed
- âœ… Runs in regular container
- âŒ Not for code execution, only editing
- âŒ Doesn't solve execution problem

#### Option B: **Direct Language Runtimes** (Python, Node, etc.)
- âœ… No privileged mode needed
- âœ… Fast execution
- âŒ **Security Risk**: User code runs directly in container
- âŒ No sandboxing/isolation
- âŒ Vulnerable to container escape

#### Option C: **Firecracker MicroVMs** (via Kata Containers)
- âœ… Hardware-level isolation
- âœ… No privileged mode in host
- âŒ **Not supported in ACA**
- âŒ Requires AKS or VMs

#### Option D: **gVisor** (User-space kernel)
- âœ… Better isolation than regular containers
- âœ… No privileged mode needed
- âŒ **Not supported in ACA**
- âŒ Requires Kubernetes

#### Option E: **Custom Sandbox** (Python `subprocess` with restrictions)
- âœ… No privileged mode needed
- âœ… Works in ACA
- âš ï¸ **Limited security**: Not as secure as Piston
- âš ï¸ Requires careful implementation

---

## âœ… Recommended Solution: Hybrid Approach

### Architecture: ACA + Azure Functions + Direct Execution

```
User Request
    â†“
Backend (ACA) - Port 8000
    â†“
Azure Function (Queue Manager)
    â†“
ACA Container (Pre-warmed Pool)
    â†“
Direct Language Runtime (Python/Node/etc.)
    â†“
Code Execution (with resource limits)
```

**Components**:

1. **Backend (ACA)**: Receives requests
2. **Azure Function**: Manages queue and container allocation
3. **ACA Container Pool**: Pre-warmed containers ready for execution
4. **Execution Engine**: Direct language runtime (Python, Node, etc.)

**Security Measures**:
- Resource limits (CPU, memory, timeout)
- Network restrictions
- File system read-only (except temp)
- Process limits
- No network access (or restricted)

---

## ğŸ“‹ Detailed Implementation Plan

### Phase 1: Replace Piston with Direct Execution

#### Step 1: Create Execution Container

**Dockerfile** (`Dockerfile.executor`):
```dockerfile
FROM python:3.11-slim

# Install language runtimes
RUN apt-get update && apt-get install -y \
    nodejs \
    openjdk-17-jdk \
    gcc g++ \
    && rm -rf /var/lib/apt/lists/*

# Create execution service
COPY executor-service.py /app/executor-service.py
WORKDIR /app

# Run as non-root user
RUN useradd -m executor && chown -R executor:executor /app
USER executor

EXPOSE 8000
CMD ["python", "executor-service.py"]
```

#### Step 2: Execution Service (Python)

**`executor-service.py`**:
```python
from flask import Flask, request, jsonify
import subprocess
import resource
import os
import tempfile
import shutil

app = Flask(__name__)

# Set resource limits
def set_limits():
    # CPU time: 10 seconds
    resource.setrlimit(resource.RLIMIT_CPU, (10, 10))
    # Memory: 256MB
    resource.setrlimit(resource.RLIMIT_AS, (256 * 1024 * 1024, 256 * 1024 * 1024))
    # Max processes: 10
    resource.setrlimit(resource.RLIMIT_NPROC, (10, 10))

@app.route('/execute', methods=['POST'])
def execute():
    data = request.json
    language = data.get('language')
    code = data.get('code')
    stdin = data.get('stdin', '')
    
    # Create temp directory
    temp_dir = tempfile.mkdtemp()
    
    try:
        set_limits()
        
        if language == 'python':
            # Write code to file
            code_file = os.path.join(temp_dir, 'main.py')
            with open(code_file, 'w') as f:
                f.write(code)
            
            # Execute with timeout
            result = subprocess.run(
                ['python3', code_file],
                input=stdin,
                capture_output=True,
                text=True,
                timeout=5,
                cwd=temp_dir,
                preexec_fn=set_limits
            )
            
            return jsonify({
                'stdout': result.stdout,
                'stderr': result.stderr,
                'code': result.returncode
            })
        
        # Add other languages...
        
    except subprocess.TimeoutExpired:
        return jsonify({
            'stdout': '',
            'stderr': 'Execution timeout',
            'code': 124
        }), 200
    except Exception as e:
        return jsonify({
            'stdout': '',
            'stderr': str(e),
            'code': 1
        }), 200
    finally:
        # Cleanup
        shutil.rmtree(temp_dir, ignore_errors=True)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000)
```

**Security Limitations**:
- âš ï¸ Not as secure as Piston (no container isolation)
- âš ï¸ User code runs in same process space
- âš ï¸ Potential for resource exhaustion
- âœ… Better than nothing (resource limits help)

---

### Phase 2: Container Pool Management

#### Option A: Pre-warmed Pool (Recommended)

**Azure Function** (`pool-manager`):
```python
import azure.functions as func
import requests
import os

# Pre-warmed container pool
POOL_SIZE = 10
CONTAINER_URL = os.environ['CONTAINER_APP_URL']

def get_available_container():
    # Check health of containers
    # Return URL of available container
    # If none available, scale up
    pass

def main(req: func.HttpRequest) -> func.HttpResponse:
    # Get execution request
    execution_request = req.get_json()
    
    # Get available container
    container_url = get_available_container()
    
    # Forward request to container
    response = requests.post(
        f"{container_url}/execute",
        json=execution_request,
        timeout=10
    )
    
    return func.HttpResponse(
        response.text,
        status_code=response.status_code
    )
```

**Pros**:
- âœ… Fast execution (~1-2 seconds)
- âœ… Containers pre-warmed
- âœ… Auto-scaling

**Cons**:
- âš ï¸ Cost: Keep containers running
- âš ï¸ Resource management needed

---

#### Option B: On-Demand Containers (Not Recommended)

**GitHub Actions Workflow**:
```yaml
name: Execute Code

on:
  workflow_dispatch:
    inputs:
      code:
        description: 'Code to execute'
        required: true
      language:
        description: 'Programming language'
        required: true

jobs:
  execute:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      
      - name: Deploy Container
        run: |
          terraform init
          terraform apply -auto-approve \
            -var="code=${{ github.event.inputs.code }}" \
            -var="language=${{ github.event.inputs.language }}"
      
      - name: Wait for Execution
        run: |
          # Poll for results
          sleep 30
      
      - name: Get Results
        run: |
          # Fetch execution results
          terraform output -json
```

**Problems**:
- âŒ **30-60 seconds latency** per execution
- âŒ GitHub Actions concurrency limits
- âŒ Not suitable for real-time use
- âŒ High cost (GitHub Actions minutes)

---

### Phase 3: Request Queue (Better than GitHub Actions)

**Azure Service Bus Queue**:
```python
from azure.servicebus import ServiceBusClient, ServiceBusMessage

# Backend sends to queue
def queue_execution(request):
    client = ServiceBusClient.from_connection_string(CONN_STR)
    with client:
        sender = client.get_queue_sender("execution-queue")
        message = ServiceBusMessage(json.dumps(request))
        sender.send_messages(message)

# Azure Function processes queue
def process_queue(message):
    # Get available container
    container = get_container_from_pool()
    
    # Execute
    result = execute_code(container, message)
    
    # Return result
    return result
```

**Pros**:
- âœ… Proper message queue
- âœ… High throughput
- âœ… Reliable
- âœ… Auto-scaling

---

## ğŸ”’ Security Comparison

| Aspect | Session Pool (Current) | ACA Direct Execution | ACA + gVisor (Not Supported) |
|--------|------------------------|---------------------|------------------------------|
| **Isolation** | Hyper-V (hardware) | Container (OS-level) | User-space kernel |
| **Security Level** | ğŸŸ¢ High | ğŸŸ¡ Medium | ğŸŸ¢ High |
| **Container Escape Risk** | âœ… Very Low | âš ï¸ Medium | âœ… Low |
| **Resource Limits** | âœ… Enforced | âœ… Enforced | âœ… Enforced |
| **Network Isolation** | âœ… Yes | âœ… Yes | âœ… Yes |

---

## ğŸ’° Cost Comparison

### Current (Session Pool)
- **Idle**: $0/day (ready-sessions: 0)
- **Active**: ~$0.10-0.50/hour per session
- **200 users, 2 hours**: ~$10-15

### Proposed (ACA Only)
- **Pre-warmed Pool (10 containers)**: ~$2-3/day
- **Per execution**: ~$0.001-0.01
- **200 users, 2 hours**: ~$5-10 (if pool-based)
- **On-demand**: ~$20-30 (if creating containers per request)

---

## âœ… Final Recommendation

### **Option 1: Keep Session Pool (Recommended)**
- âœ… Best security (Hyper-V isolation)
- âœ… Fast execution
- âœ… Cost-effective
- âœ… Already working (just needs ingress fix)

**Action**: Fix ingress issue, continue using Session Pool

---

### **Option 2: ACA + Pre-warmed Pool + Direct Execution**
- âœ… No privileged mode needed
- âœ… Standard ACA features
- âš ï¸ Less secure than Session Pool
- âš ï¸ Requires custom execution engine

**Implementation**:
1. Replace Piston with direct language runtimes
2. Use Azure Functions for queue management
3. Maintain pre-warmed container pool
4. Implement resource limits and security measures

---

### **Option 3: Hybrid (Session Pool + ACA Fallback)**
- âœ… Best of both worlds
- âœ… Session Pool for security-critical code
- âœ… ACA for simple/trusted code
- âš ï¸ More complex

---

## ğŸ“‹ Proof of Concept Plan

### Step 1: Create Execution Container (1-2 days)
- [ ] Build Dockerfile with language runtimes
- [ ] Create execution service (Python/Node)
- [ ] Test basic code execution
- [ ] Implement resource limits

### Step 2: Deploy to ACA (1 day)
- [ ] Deploy container to ACA
- [ ] Test execution endpoint
- [ ] Verify resource limits work
- [ ] Test security measures

### Step 3: Create Pool Manager (2-3 days)
- [ ] Azure Function for queue management
- [ ] Container pool management logic
- [ ] Health checks
- [ ] Auto-scaling

### Step 4: Integration (2-3 days)
- [ ] Update backend to use new system
- [ ] Test end-to-end flow
- [ ] Load testing
- [ ] Security testing

### Step 5: Comparison Testing (1-2 days)
- [ ] Compare with Session Pool
- [ ] Performance benchmarks
- [ ] Cost analysis
- [ ] Security assessment

**Total**: ~7-11 days for POC

---

## ğŸ¯ Decision Matrix

| Criteria | Session Pool | ACA Direct | ACA + Queue |
|----------|--------------|------------|-------------|
| **Security** | ğŸŸ¢ High | ğŸŸ¡ Medium | ğŸŸ¡ Medium |
| **Speed** | ğŸŸ¢ Fast (1-3s) | ğŸŸ¢ Fast (1-2s) | ğŸŸ¡ Medium (2-5s) |
| **Cost** | ğŸŸ¢ Low | ğŸŸ¡ Medium | ğŸŸ¡ Medium |
| **Complexity** | ğŸŸ¡ Medium | ğŸŸ¢ Low | ğŸ”´ High |
| **Scalability** | ğŸŸ¢ High | ğŸŸ¢ High | ğŸŸ¢ High |
| **Privileged Mode** | âœ… Not needed | âœ… Not needed | âœ… Not needed |

---

## ğŸ“ Conclusion

**Your senior's suggestion has merit BUT**:

1. âœ… **ACA-only is possible** (with direct execution, not Piston)
2. âš ï¸ **GitHub Actions is NOT ideal** for request queuing (use Azure Service Bus)
3. âš ï¸ **On-demand containers are too slow** (use pre-warmed pool)
4. âš ï¸ **Security is reduced** (container-level vs hardware-level)

**Recommendation**: 
- **Short-term**: Fix Session Pool ingress issue (easiest)
- **Long-term**: Evaluate ACA + Direct Execution if Session Pool doesn't meet needs

---

**Next Steps**: 
1. Fix current Session Pool ingress issue
2. Create POC of ACA + Direct Execution
3. Compare both approaches
4. Make informed decision


